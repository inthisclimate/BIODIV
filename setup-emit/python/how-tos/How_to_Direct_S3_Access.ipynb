{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to: Use Direct S3 Access to work with EMIT Data\n",
    "\n",
    "**Summary**  \n",
    "\n",
    "EMIT datasets are available through NASA's Earthdata Cloud. NASA Earthdata on Cloud is always free and accessible via either HTTPS or direct S3 bucket access. With direct S3 access, you can bring your \"code to the data\", making your processing faster and scalable. Direct S3 access to NASA Earthdata on Cloud is only available if your Amazon Web Services (AWS) instance is set up in the `us-west-2` region. This notebook explains how to utilize direct S3 access to EMIT data. \n",
    "\n",
    "**Requirements**\n",
    "\n",
    "+ A NASA [Earthdata Login](https://urs.earthdata.nasa.gov/) account is required to download EMIT data\n",
    "+ A configured `.netrc` file to access NASA Earth Data\n",
    "  + This will be configured in the notebook using the `earthaccess` python library. \n",
    "+ Selected the `emit_tutorials` environment as the kernel for this notebook.\n",
    "  + For instructions on setting up the environment, follow the `setup_instructions.md` included in the `/setup/` folder of the repository. \n",
    "+ **xarray v2022.12.0** or newer to read s3 files multiple times when open with s3fs\n",
    "  + Version can be checked in Python using `xarray.__version__`\n",
    "  + To update, activate your environment and enter `pip install xarray==2022.12.0` in command line.\n",
    "\n",
    "**Learning Objectives**  \n",
    "+ How to use Direct S3 Access to EMIT Data\n",
    "+ How to add this functionality to any notebook from this repository\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import s3fs\n",
    "import netCDF4 as nc\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import earthaccess\n",
    "sys.path.append('../modules/')\n",
    "from emit_tools import emit_xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overview of s3 Access\n",
    "\n",
    "NASA Earthdata Cloud data in S3 can be directly accessed via temporary credentials; this access is limited to requests made within the US West (Oregon) (code: us-west-2) AWS region. Direct S3 access is achieved by passing NASA supplied temporary credentials (token) to AWS so we can interact with S3 objects from applicable Earthdata Cloud buckets. Your NASA Earthdata login credentials can easily be managed using the `earthaccess` library. We can create the necessary `.netrc` file that stores the Earthdata Login credentials locally with the following code cell. Enter your username and password if prompted, these will be used to sign into NASA Earthdata and retrieve the necessary temporary credentials allowing you to utilize s3 access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The persist option creates and stores your username and password in a .netrc file\n",
    "earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, each NASA DAAC has different AWS credentials endpoints. Below are some of the credential endpoints to various DAACs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_cred_endpoint = {\n",
    "    'podaac':'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n",
    "    'gesdisc': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials',\n",
    "    'lpdaac':'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials',\n",
    "    'ornldaac': 'https://data.ornldaac.earthdata.nasa.gov/s3credentials',\n",
    "    'ghrcdaac': 'https://data.ghrc.earthdata.nasa.gov/s3credentials'\n",
    "}\n",
    "s3_cred_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to make a request to an endpoint for temporary credentials. Remember, each DAAC has their own endpoint and credentials are not usable for cloud data from other DAACs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Function \n",
    "def get_temp_creds(provider):\n",
    "    return requests.get(s3_cred_endpoint[provider]).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Credentials\n",
    "temp_creds_req = get_temp_creds('lpdaac')\n",
    "#temp_creds_req"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up an s3fs Session for Direct Access\n",
    "\n",
    "`s3fs` sessions are used for authenticated access to s3 bucket and allows for typical file-system style operations. Below we create session by passing in the temporary credentials we recieved from our temporary credentials endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass Authentication to s3fs\n",
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=temp_creds_req['accessKeyId'], \n",
    "                          secret=temp_creds_req['secretAccessKey'], \n",
    "                          token=temp_creds_req['sessionToken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we specify the s3 URL to the data asset in Earthdata Cloud. This URL can be found via Earthdata Search or programmatically through the CMR and CMR-STAC APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define S3 URL                          \n",
    "s3_url = 's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open with the netCDF file using the s3fs package, then load the cloud asset into an xarray dataset, or use directly with `emit_xarray` function from `emit_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open s3 url\n",
    "fp = fs_s3.open(s3_url, mode='rb')\n",
    "# Open dataset with xarray\n",
    "ds = xr.open_dataset(fp) #Note this only opens the root group (reflectance)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open and Orthorectify\n",
    "ds = emit_xarray(fp, ortho=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot Spatially\n",
    "ds.sel(wavelengths=650, method='nearest').hvplot.image(cmap='viridis', aspect = 'equal', frame_width=500, rasterize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plot Spectra at a Location\n",
    "ds.sel(longitude=-61.833,latitude=-39.710,method='nearest').hvplot.line(y='reflectance',x='wavelengths', color='black', frame_width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## S3 Access for any Notebook in this Repository\n",
    "\n",
    "Add the two code blocks below to any how-to or tutorial notebook, by replacing the block that sets the local filepath(s) as `fp` with the two blocks below. The first block imports the additional packages required and retrieves temporary s3 credentials. The second uses `s3fs` to open the desired s3 URL and create an object readable by `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import s3fs\n",
    "import earthaccess\n",
    "\n",
    "# Use Earthaccess to Manage NASA Earthdata Credentials and create .netrc if necessary\n",
    "earthaccess.login(persist=True)\n",
    "\n",
    "# Get Temporary Credentials/Token\n",
    "temp_creds_req = requests.get('https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials').json() # use lpdaac credential endpoint for EMIT data\n",
    "\n",
    "# Create s3fs session\n",
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=temp_creds_req['accessKeyId'], \n",
    "                          secret=temp_creds_req['secretAccessKey'], \n",
    "                          token=temp_creds_req['sessionToken'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set s3 url and open\n",
    "s3_url = 's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_RFL_001_20220903T163129_2224611_012.nc' # S3 URL to L2A Reflectance File used throughout tutorial\n",
    "#s3_url_mask = 's3://lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20220903T163129_2224611_012/EMIT_L2A_MASK_001_20220903T163129_2224611_012.nc' # Only used for Quality How-to\n",
    "fp = fs_s3.open(s3_url, mode='rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to proceed as normal through the other Jupyter notebooks at the step opening the file with `emit_xarray` from the `emit_tools` module or `xarray.open_dataset` depending on the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Contact Info:  \n",
    "\n",
    "Email: LPDAAC@usgs.gov  \n",
    "Voice: +1-866-573-3222  \n",
    "Organization: Land Processes Distributed Active Archive Center (LP DAAC)¹  \n",
    "Website: <https://lpdaac.usgs.gov/>  \n",
    "Date last modified: 08-03-2023  \n",
    "\n",
    "¹Work performed under USGS contract G15PD00467 for NASA contract NNG14HH33I.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "3292b2aceff7d39327a7519422d4180a7c9b133202090f26e797e3dd8f2c7877"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
